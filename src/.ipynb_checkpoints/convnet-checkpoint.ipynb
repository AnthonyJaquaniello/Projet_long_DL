{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification des poches protéiques en fonction du type de druggabilité, par un CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from random import sample\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
    "from keras.layers import add, Activation\n",
    "from keras.layers import Conv3D, MaxPool3D\n",
    "from keras.models import Sequential, load_model\n",
    "from os import listdir\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"/media/anthony/POULOP/deepdrug3d_voxel_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equilibrator_samplor(path, nucleotid, heme, control, steroid, k):\n",
    "    all_pocket = listdir(path)\n",
    "    ech = sample(nucleotid, k) + sample(heme, k) + sample(control, k)\n",
    "    shuffle(ech)\n",
    "    chosen_pocket = [pocket for pocket in all_pocket if pocket in ech]\n",
    "    return chosen_pocket\n",
    "\n",
    "def remove_list(chosen_pocket, nucleotid, heme, control, steroid):\n",
    "    for pocket in chosen_pocket:\n",
    "        if pocket in nucleotid:\n",
    "            nucleotid.remove(pocket)\n",
    "        elif pocket in heme:\n",
    "            heme.remove(pocket)\n",
    "        elif pocket in control:\n",
    "            control.remove(pocket)\n",
    "        elif pocket in steroid:\n",
    "            steroid.remove(pocket)\n",
    "\n",
    "def load_x(path, chosen_pocket):\n",
    "    try:\n",
    "        X = [np.load(\"{}/{}\".format(path, pocket))\n",
    "             for pocket in chosen_pocket]\n",
    "    except ValueError:\n",
    "        print(pocket)\n",
    "    X = [np.squeeze(array) for array in X]\n",
    "    X = np.array(X)\n",
    "    X = np.moveaxis(X, 1, -1)\n",
    "    return X\n",
    "\n",
    "def load_y(chosen_pocket, nucleotid, heme, control, steroid):\n",
    "    Y = []\n",
    "    for pocket in chosen_pocket:\n",
    "        if pocket in nucleotid:\n",
    "            Y.append(1)\n",
    "        elif pocket in heme:\n",
    "            Y.append(2)\n",
    "        elif pocket in steroid:\n",
    "            Y.append(4)\n",
    "        elif pocket in control:\n",
    "            Y.append(3)\n",
    "    Y  = np.array(Y)\n",
    "    return Y\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "    classes = LabelEncoder()\n",
    "    integer_encoding = classes.fit_transform(y)\n",
    "    one_hot_Y = keras.utils.to_categorical(integer_encoding)\n",
    "    return one_hot_Y\n",
    "\n",
    "def list_generator(file):\n",
    "    with open(file, \"r\") as filin:\n",
    "        liste = [\"{}.npy\".format(line[:-1]) for line in filin]\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotid = list_generator(\"nucleotide.list.txt\")\n",
    "heme = list_generator(\"heme.list.txt\")\n",
    "steroid = list_generator(\"steroid.list.txt\")\n",
    "control = list_generator(\"control.list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553\n",
      "596\n",
      "1946\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "print(len(nucleotid))\n",
    "print(len(heme))\n",
    "print(len(control))\n",
    "print(len(steroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1478\n",
      "521\n",
      "1871\n",
      "69\n"
     ]
    }
   ],
   "source": [
    "train_pocket = equilibrator_samplor(PATH_DATA, nucleotid, heme, control, steroid, 75)\n",
    "X_train = load_x(PATH_DATA, train_pocket)\n",
    "Y_train = load_y(train_pocket, nucleotid, heme, control, steroid)\n",
    "one_hot_Y_train = one_hot_encoding(Y_train)\n",
    "\n",
    "remove_list(train_pocket, nucleotid, heme, control, steroid)\n",
    "print(len(nucleotid))\n",
    "print(len(heme))\n",
    "print(len(control))\n",
    "print(len(steroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 32, 32, 32, 14)\n",
      "(75, 32, 32, 32, 14)\n",
      "225\n",
      "75\n",
      "(225, 3)\n",
      "(75, 3)\n"
     ]
    }
   ],
   "source": [
    "test_pocket = equilibrator_samplor(PATH_DATA, nucleotid, heme, control, steroid, 25)\n",
    "X_test = load_x(PATH_DATA, test_pocket)\n",
    "Y_test = load_y(test_pocket, nucleotid, heme, control, steroid)\n",
    "one_hot_Y_test = one_hot_encoding(Y_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(len(Y_train))\n",
    "print(len(Y_test))\n",
    "print(one_hot_Y_train.shape)\n",
    "print(one_hot_Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pocket in train_pocket:\n",
    "    if pocket in test_pocket:\n",
    "        print(\"putain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt= 0\n",
    "hem = 0\n",
    "ste = 0\n",
    "ctr = 0\n",
    "\n",
    "for i in range(0, one_hot_Y_train.shape[0]):\n",
    "    if one_hot_Y_train[i,0]:\n",
    "        ctr += 1\n",
    "    elif one_hot_Y_train[i,1]:\n",
    "        nt += 1\n",
    "    elif one_hot_Y_train[i,2]:\n",
    "        hem += 1\n",
    "    else:\n",
    "        ste += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "75\n",
      "0\n",
      "75\n",
      "75+75+0+75 = 225\n",
      "225\n"
     ]
    }
   ],
   "source": [
    "print(nt)\n",
    "print(hem)\n",
    "print(ste)\n",
    "print(ctr)\n",
    "print(\"{}+{}+{}+{} = {}\".format(nt,hem,ste,ctr, nt+hem+ste+ctr))\n",
    "print(len(one_hot_Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_one():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(filters =64, kernel_size = (28,28,28), data_format=\"channels_last\", strides=1, padding= \"same\", activation = \"relu\"))\n",
    "    model.add(Conv3D(filters = 64, kernel_size = (26,26,26), data_format=\"channels_last\", strides=1, padding= \"same\", activation = \"relu\"))\n",
    "    #model.add(Conv3D(filters = 8, kernel_size = 3, data_format=\"channels_last\", strides=1, padding= \"same\", activation = \"relu\", kernel_initializer=\"he_normal\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPool3D(pool_size = 2, strides = 1, padding = \"same\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 75, activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(units = 3, activation = \"softmax\"))\n",
    "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 202 samples, validate on 23 samples\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2000)\n",
    "critor = EarlyStopping(monitor = \"val_loss\", patience = 4, mode = \"min\")\n",
    "my_model = model_one()\n",
    "\n",
    "#best_model_path = \"../results/my_model\"+\".h5\"\n",
    "#best_model = ModelCheckpoint(best_model_path, monitor = \"val_loss\", verbose = 2, save_best_only = True)\n",
    "#my_best_model = load_model(\"../results/my_model.h5\")\n",
    "\n",
    "my_model.fit(X_train, one_hot_Y_train, epochs = 15, batch_size = 50,\n",
    "             validation_split = 0.1, callbacks = [critor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 10s 106ms/step\n",
      "[1.0986277310535162, 0.3333333432674408]\n"
     ]
    }
   ],
   "source": [
    "evaluation = my_model.evaluate(X_test, one_hot_Y_test)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = KerasClassifier(build_fn = model_one, epochs = 5, batch_size=20, verbose=0)\n",
    "kfold = KFold(n_splits = 5, shuffle=True)\n",
    "cv_result = cross_val_score(training, X_train, one_hot_Y_train, cv = kfold)\n",
    "print(cv_result)\n",
    "print(\"%.2f%%(%2d%%)\"%(cv_result.mean()*100, cv_result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    maxi = max(predictions[i,:])\n",
    "    if maxi == predictions[i, 0]:\n",
    "        classe = 0\n",
    "    elif maxi == predictions[i,1]:\n",
    "        classe = 1\n",
    "    elif maxi == predictions[i,2]:\n",
    "        classe = 2\n",
    "        \n",
    "    if (one_hot_Y_test[i, 0] == 1.0) and (classe == 0):\n",
    "        tp += 1\n",
    "    elif (one_hot_Y_test[i, 1] == 1.0) and (classe == 1):\n",
    "        tp += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 1.0) and (classe == 0):\n",
    "        fp += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 1.0) and (classe == 1):\n",
    "        fp += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 1.0) and (classe == 2):\n",
    "        tn += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 0.0) and (classe == 2):\n",
    "        fn += 1\n",
    "        \n",
    "from math import sqrt\n",
    "\n",
    "print(\"TP:{:.2f}%\".format(tp*100/len(predictions)))\n",
    "print(\"FP:{:.2f}%\".format(fp*100/len(predictions)))\n",
    "print(\"TN:{:.2f}\".format(tn*100/len(predictions)))\n",
    "print(\"FN:{:.2f}\".format(fn*100/len(predictions)))\n",
    "print(\"ACC = {:.2f}%\".format((tp+tn)*100/(tp+tn+fp+fn)))\n",
    "print(\"PPV = {:.2f}%\".format(tp*100/(tp+fp)))\n",
    "print(\"TNR = {:.2f}%\".format(tn*100/(tn+fp)))\n",
    "print(\"TPR = {:.2f}%\".format(tp*100/(tp+fn)))\n",
    "print(\"FPR = {:.2f}%\".format(fp*100/(fp+tn)))\n",
    "print(\"MCC = {:.2f}\".format(((tn*tp)-(fp*fn))/sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
