{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification des poches protéiques en fonction du type de druggabilité, par un CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from random import sample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
    "from keras.layers import add, Activation\n",
    "from keras.layers import Conv3D, MaxPool3D\n",
    "from keras.models import Sequential, load_model\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"/media/anthony/POULOP/deepdrug3d_voxel_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdir(PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equilibrator_samplor(path, nucleotid, heme, control, steroid, k):\n",
    "    all_pocket = listdir(path)\n",
    "    ech = sample(nucleotid, k) + sample(heme, k) + sample(control, k)\n",
    "    shuffle(ech)\n",
    "    return ech\n",
    "\n",
    "def remove_list(chosen_pocket, nucleotid, heme, control, steroid):\n",
    "    for pocket in chosen_pocket:\n",
    "        if pocket in nucleotid:\n",
    "            nucleotid.remove(pocket)\n",
    "        elif pocket in heme:\n",
    "            heme.remove(pocket)\n",
    "        elif pocket in control:\n",
    "            control.remove(pocket)\n",
    "        elif pocket in steroid:\n",
    "            steroid.remove(pocket)\n",
    "\n",
    "def load_x(path, chosen_pocket): #!\n",
    "    X = np.zeros((len(chosen_pocket),14,32,32,32))\n",
    "    for i in range(0,len(chosen_pocket)):\n",
    "        X[i,:,:,:,:] = np.load(\"{}{}\".format(path, chosen_pocket[i]))\n",
    "        np.squeeze(X[i,:,:,:,:])\n",
    "    return X\n",
    "\n",
    "def load_y(chosen_pocket, nucleotid, heme, control, steroid):\n",
    "    Y = []\n",
    "    for pocket in chosen_pocket:\n",
    "        if pocket in nucleotid:\n",
    "            Y.append(1)\n",
    "        elif pocket in heme:\n",
    "            Y.append(2)\n",
    "        elif pocket in steroid:\n",
    "            Y.append(4)\n",
    "        elif pocket in control:\n",
    "            Y.append(3)\n",
    "    Y  = np.array(Y)\n",
    "    return Y\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "    classes = LabelEncoder()\n",
    "    integer_encoded = classes.fit_transform(y)\n",
    "    one_hot = keras.utils.to_categorical(integer_encoded, num_classes= 3) \n",
    "    return one_hot\n",
    "\n",
    "def list_generator(file):\n",
    "    with open(file, \"r\") as filin:\n",
    "        liste = [\"{}.npy\".format(line[:-1]) for line in filin]\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946 596 1553 69\n"
     ]
    }
   ],
   "source": [
    "def read_list_file(filepath, group):\n",
    "    with open(filepath, \"r\") as filin:\n",
    "        listin = {}\n",
    "        for line in filin:\n",
    "            listin[line[:-1]] = group\n",
    "    return listin\n",
    "\n",
    "def split_train_val(all_dic, train_size, test_size, PATH_DATA):\n",
    "\n",
    "    if train_size + test_size > len(all_dic):\n",
    "        print(\"train_size and test_size are too big, changing to 50/50\")\n",
    "        train_size = len(all_dic) / 2\n",
    "        test_size = train_size\n",
    "\n",
    "    X_train_id = sample(list(all_dic), train_size)\n",
    "    X_fullval_id = [item for item in list(all_dic) if item not in X_train_id]\n",
    "    X_val_id = sample(X_fullval_id, test_size)\n",
    "\n",
    "    X_train = np.zeros((len(X_train_id), 14, 32, 32, 32))\n",
    "    X_val = np.zeros((len(X_val_id), 14, 32, 32, 32))\n",
    "    Y_train = np.zeros((len(X_train_id), 3))\n",
    "    Y_val = np.zeros((len(X_val_id), 3))\n",
    "\n",
    "    for i in range(len(X_train_id)):\n",
    "        X_train[i,:,:,:,:] = np.load(\n",
    "            PATH_DATA + X_train_id[i] + \".npy\"\n",
    "            )\n",
    "        Y_train[i,:] = all_dic[X_train_id[i]]\n",
    "\n",
    "    for i in range(len(X_val_id)):\n",
    "        X_val[i,:,:,:,:] = np.load(\n",
    "            PATH_DATA + X_val_id[i] + \".npy\"\n",
    "            )\n",
    "        Y_val[i,:] = all_dic[X_val_id[i]]\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "control_file = \"control.list.txt\"\n",
    "heme_file = \"heme.list.txt\"\n",
    "nucleotide_file = \"nucleotide.list.txt\"\n",
    "steroid_file = \"steroid.list.txt\"\n",
    "\n",
    "control_id = read_list_file(control_file,[0, 0, 1])\n",
    "heme_id = read_list_file(heme_file, [0, 1, 0])\n",
    "nucleotide_id = read_list_file(nucleotide_file, [1, 0, 0])\n",
    "steroid_id = read_list_file(steroid_file, 4)\n",
    "\n",
    "print(len(control_id), len(heme_id), len(nucleotide_id), len(steroid_id))\n",
    "\n",
    "all_dic = control_id\n",
    "all_dic.update(heme_id)\n",
    "all_dic.update(nucleotide_id)\n",
    "#all_dic.update(steroid_id)\n",
    "\n",
    "X_train, Y_train, X_val, Y_val = split_train_val(all_dic, 100 , 50, PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotid = list_generator(\"nucleotide.list.txt\")\n",
    "heme = list_generator(\"heme.list.txt\")\n",
    "steroid = list_generator(\"steroid.list.txt\")\n",
    "control = list_generator(\"control.list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nucleotid))\n",
    "print(len(heme))\n",
    "print(len(control))\n",
    "print(len(steroid))\n",
    "print(len(nucleotid)+len(heme)+len(control)+len(steroid))\n",
    "print(len(listdir(PATH_DATA)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pocket = equilibrator_samplor(PATH_DATA, nucleotid, heme, control, steroid, 75)\n",
    "X_train = load_x(PATH_DATA, train_pocket)\n",
    "Y_train = load_y(train_pocket, nucleotid, heme, control, steroid)\n",
    "one_hot_Y_train = one_hot_encoding(Y_train)\n",
    "remove_list(train_pocket, nucleotid, heme, control, steroid)\n",
    "\n",
    "print(len(nucleotid))\n",
    "print(len(heme))\n",
    "print(len(control))\n",
    "print(len(steroid))\n",
    "print(len(train_pocket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pocket = equilibrator_samplor(PATH_DATA, nucleotid, heme, control, steroid, 25)\n",
    "X_test = load_x(PATH_DATA, test_pocket)\n",
    "Y_test = load_y(test_pocket, nucleotid, heme, control, steroid)\n",
    "one_hot_Y_test = one_hot_encoding(Y_test)\n",
    "print(X_train.shape)\n",
    "print(type(X_train))\n",
    "print(X_test.shape)\n",
    "print(type(X_test))\n",
    "print(len(Y_train))\n",
    "print(type(Y_train))\n",
    "print(len(Y_test))\n",
    "print(type(Y_test))\n",
    "print(one_hot_Y_train.shape)\n",
    "print(type(one_hot_Y_train))\n",
    "print(one_hot_Y_test.shape)\n",
    "print(type(one_hot_Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pocket in train_pocket:\n",
    "    if pocket in test_pocket:\n",
    "        print(\"putain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt= 0\n",
    "hem = 0\n",
    "ste = 0\n",
    "ctr = 0\n",
    "\n",
    "for i in range(0, one_hot_Y_train.shape[0]):\n",
    "    if one_hot_Y_train[i,0]:\n",
    "        ctr += 1\n",
    "    elif one_hot_Y_train[i,1]:\n",
    "        nt += 1\n",
    "    elif one_hot_Y_train[i,2]:\n",
    "        hem += 1\n",
    "    else:\n",
    "        ste += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nt)\n",
    "print(hem)\n",
    "print(ste)\n",
    "print(ctr)\n",
    "print(\"{}+{}+{}+{} = {}\".format(nt,hem,ste,ctr, nt+hem+ste+ctr))\n",
    "print(len(one_hot_Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nique():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(filters = 14, kernel_size = 5, data_format=\"channels_first\",\n",
    "                     strides=1, padding= \"valid\", activation = \"relu\", kernel_initializer=\"he_normal\",\n",
    "                     input_shape = (14,32,32,32)))\n",
    "    model.add(Conv3D(filters = 14, kernel_size = 3, data_format=\"channels_first\", strides=1, padding= \"valid\", activation = \"relu\"))\n",
    "    model.add(Dropout(rate = 0.3))\n",
    "    model.add(MaxPool3D(pool_size = 2, strides = 1, padding = \"valid\"))\n",
    "    model.add(Dropout(rate = 0.3))\n",
    "    model.add(Flatten(data_format = \"channels_first\"))\n",
    "    model.add(Dense(units = 100, activation = \"relu\"))\n",
    "    model.add(Dropout(rate = 0.3))\n",
    "    model.add(Dense(units = 3, activation = \"softmax\"))\n",
    "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90 samples, validate on 10 samples\n",
      "Epoch 1/10\n",
      "90/90 [==============================] - 11s 120ms/step - loss: 101.1790 - accuracy: 0.3333 - val_loss: 1.0967 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "90/90 [==============================] - 10s 107ms/step - loss: 1.0983 - accuracy: 0.4000 - val_loss: 1.0973 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 1.0970 - accuracy: 0.3778 - val_loss: 1.0945 - val_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 1.0955 - accuracy: 0.3778 - val_loss: 1.0918 - val_accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "90/90 [==============================] - 10s 106ms/step - loss: 1.0936 - accuracy: 0.3778 - val_loss: 1.0892 - val_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "90/90 [==============================] - 9s 104ms/step - loss: 1.0913 - accuracy: 0.3778 - val_loss: 1.0866 - val_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "90/90 [==============================] - 9s 105ms/step - loss: 1.0902 - accuracy: 0.3778 - val_loss: 1.0838 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "90/90 [==============================] - 9s 105ms/step - loss: 1.0889 - accuracy: 0.3778 - val_loss: 1.0809 - val_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "90/90 [==============================] - 10s 111ms/step - loss: 1.0866 - accuracy: 0.3778 - val_loss: 1.0781 - val_accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "90/90 [==============================] - 9s 105ms/step - loss: 1.0850 - accuracy: 0.3778 - val_loss: 1.0753 - val_accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f784fea4a50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2000)\n",
    "critor = EarlyStopping(monitor = \"val_loss\", patience = 3, mode = \"min\")\n",
    "model_lol = model_nique()\n",
    "\n",
    "#best_model_path = \"../results/my_model\"+\".h5\"\n",
    "#best_model = ModelCheckpoint(best_model_path, monitor = \"val_loss\", verbose = 2, save_best_only = True)\n",
    "#my_best_model = load_model(\"../results/my_model.h5\")\n",
    "\n",
    "model_lol.fit(X_train, Y_train, epochs = 10, batch_size = 20,\n",
    "             validation_split = 0.1, callbacks = [critor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_3 (Conv3D)            (None, 14, 28, 28, 28)    24514     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 14, 26, 26, 26)    5306      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 26, 26, 26)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 13, 25, 25, 26)    0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 13, 25, 25, 26)    0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 211250)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               21125100  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 21,155,223\n",
      "Trainable params: 21,155,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lol.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 2s 42ms/step\n",
      "[1.0683499813079833, 0.4399999976158142]\n"
     ]
    }
   ],
   "source": [
    "evaluation = model_lol.evaluate(X_val, Y_val, batch_size = 10, callbacks = [critor])\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = KerasClassifier(build_fn = model_one, epochs = 5, batch_size=20, verbose=0)\n",
    "kfold = KFold(n_splits = 5, shuffle=True)\n",
    "cv_result = cross_val_score(training, X_train, one_hot_Y_train, cv = kfold)\n",
    "print(cv_result)\n",
    "print(\"%.2f%%(%2d%%)\"%(cv_result.mean()*100, cv_result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lol.predict(X_train, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n",
      "[0.34533304 0.31282264 0.34184432]\n"
     ]
    }
   ],
   "source": [
    "for p in predictions:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    maxi = max(predictions[i,:])\n",
    "    if maxi == predictions[i, 0]:\n",
    "        classe = 0\n",
    "    elif maxi == predictions[i,1]:\n",
    "        classe = 1\n",
    "    elif maxi == predictions[i,2]:\n",
    "        classe = 2\n",
    "        \n",
    "    if (one_hot_Y_test[i, 0] == 1.0) and (classe == 0):\n",
    "        tp += 1\n",
    "    elif (one_hot_Y_test[i, 1] == 1.0) and (classe == 1):\n",
    "        tp += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 1.0) and (classe == 0):\n",
    "        fp += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 1.0) and (classe == 1):\n",
    "        fp += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 1.0) and (classe == 2):\n",
    "        tn += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 0.0) and (classe == 2):\n",
    "        fn += 1\n",
    "        \n",
    "from math import sqrt\n",
    "\n",
    "print(\"TP:{:.2f}%\".format(tp*100/len(predictions)))\n",
    "print(\"FP:{:.2f}%\".format(fp*100/len(predictions)))\n",
    "print(\"TN:{:.2f}\".format(tn*100/len(predictions)))\n",
    "print(\"FN:{:.2f}\".format(fn*100/len(predictions)))\n",
    "print(\"ACC = {:.2f}%\".format((tp+tn)*100/(tp+tn+fp+fn)))\n",
    "print(\"PPV = {:.2f}%\".format(tp*100/(tp+fp)))\n",
    "print(\"TNR = {:.2f}%\".format(tn*100/(tn+fp)))\n",
    "print(\"TPR = {:.2f}%\".format(tp*100/(tp+fn)))\n",
    "print(\"FPR = {:.2f}%\".format(fp*100/(fp+tn)))\n",
    "print(\"MCC = {:.2f}\".format(((tn*tp)-(fp*fn))/sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
