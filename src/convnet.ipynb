{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification des poches protéiques en fonction du type de druggabilité, par un CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import Input, Model\n",
    "import numpy as np\n",
    "from random import shuffle, sample, randint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
    "from keras.layers import add, Activation, Conv3D, MaxPooling3D, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"/media/anthony/POULOP/deepdrug3d_voxel_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equilibrator_samplor(path, nucleotid, heme, control, steroid, k):\n",
    "    all_pocket = listdir(path)\n",
    "    ech = sample(nucleotid, randint(k-15, k+15)) + sample(heme, randint(k-15, k+15)) + sample(control, randint(k-15, k+15))\n",
    "    shuffle(ech)\n",
    "    return ech\n",
    "\n",
    "def remove_list(chosen_pocket, nucleotid, heme, control, steroid):\n",
    "    for pocket in chosen_pocket:\n",
    "        if pocket in nucleotid:\n",
    "            nucleotid.remove(pocket)\n",
    "        elif pocket in heme:\n",
    "            heme.remove(pocket)\n",
    "        elif pocket in control:\n",
    "            control.remove(pocket)\n",
    "        elif pocket in steroid:\n",
    "            steroid.remove(pocket)\n",
    "\n",
    "def load_x(path, chosen_pocket):\n",
    "    X = np.zeros((len(chosen_pocket),14,32,32,32))\n",
    "    for i in range(0, len(chosen_pocket)):\n",
    "        X[i,:,:,:,:] = np.load(\"{}{}\".format(path, chosen_pocket[i]))\n",
    "        if X[i,:,:,:,:].shape == (1,14,32,32,32):\n",
    "            np.squeeze(X[i,:,:,:,:])\n",
    "    return X\n",
    "\n",
    "def load_y(chosen_pocket, nucleotid, heme, control, steroid):\n",
    "    Y = np.zeros((len(chosen_pocket),3))\n",
    "    for i in range(0, len(chosen_pocket)):\n",
    "        if chosen_pocket[i] in nucleotid:\n",
    "            Y[i,0] = 1\n",
    "        elif chosen_pocket[i] in heme:\n",
    "            Y[i,1] = 1\n",
    "        elif chosen_pocket[i] in control:\n",
    "            Y[i,2] = 1\n",
    "    return Y\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "    classes = LabelEncoder()\n",
    "    integer_encoded = classes.fit_transform(y)\n",
    "    one_hot = keras.utils.to_categorical(integer_encoded, num_classes= 3) \n",
    "    return one_hot\n",
    "\n",
    "def list_generator(file):\n",
    "    with open(file, \"r\") as filin:\n",
    "        liste = [\"{}.npy\".format(line[:-1]) for line in filin]\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleotid = list_generator(\"nucleotide.list.txt\")\n",
    "heme = list_generator(\"heme.list.txt\")\n",
    "steroid = list_generator(\"steroid.list.txt\")\n",
    "control = list_generator(\"control.list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553\n",
      "596\n",
      "1946\n",
      "69\n",
      "4164\n",
      "4164\n"
     ]
    }
   ],
   "source": [
    "print(len(nucleotid))\n",
    "print(len(heme))\n",
    "print(len(control))\n",
    "print(len(steroid))\n",
    "print(len(nucleotid)+len(heme)+len(control)+len(steroid))\n",
    "print(len(listdir(PATH_DATA)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453\n",
      "497\n",
      "1848\n",
      "69\n",
      "297\n"
     ]
    }
   ],
   "source": [
    "train_pocket = equilibrator_samplor(PATH_DATA, nucleotid, heme, control, steroid, 100)\n",
    "X_train = load_x(PATH_DATA, train_pocket)\n",
    "one_hot_Y_train = load_y(train_pocket, nucleotid, heme, control, steroid)\n",
    "#one_hot_Y_train = one_hot_encoding(Y_train)\n",
    "remove_list(train_pocket, nucleotid, heme, control, steroid)\n",
    "\n",
    "print(len(nucleotid))\n",
    "print(len(heme))\n",
    "print(len(control))\n",
    "print(len(steroid))\n",
    "print(len(train_pocket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 14, 32, 32, 32)\n",
      "<class 'numpy.ndarray'>\n",
      "(319, 14, 32, 32, 32)\n",
      "<class 'numpy.ndarray'>\n",
      "(297, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "(319, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "test_pocket = equilibrator_samplor(PATH_DATA, nucleotid, heme, control, steroid, 100)\n",
    "X_test = load_x(PATH_DATA, test_pocket)\n",
    "one_hot_Y_test = load_y(test_pocket, nucleotid, heme, control, steroid)\n",
    "#one_hot_Y_test = one_hot_encoding(Y_test)\n",
    "print(X_train.shape)\n",
    "print(type(X_train))\n",
    "print(X_test.shape)\n",
    "print(type(X_test))\n",
    "#print(len(Y_train))\n",
    "#print(type(Y_train))\n",
    "#print(len(Y_test))\n",
    "#print(type(Y_test))\n",
    "print(one_hot_Y_train.shape)\n",
    "print(type(one_hot_Y_train))\n",
    "print(one_hot_Y_test.shape)\n",
    "print(type(one_hot_Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pocket in train_pocket:\n",
    "    if pocket in test_pocket:\n",
    "        print(\"putain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt= 0\n",
    "hem = 0\n",
    "ste = 0\n",
    "ctr = 0\n",
    "\n",
    "for i in range(0, one_hot_Y_train.shape[0]):\n",
    "    if one_hot_Y_train[i,0]:\n",
    "        ctr += 1\n",
    "    elif one_hot_Y_train[i,1]:\n",
    "        nt += 1\n",
    "    elif one_hot_Y_train[i,2]:\n",
    "        hem += 1\n",
    "    else:\n",
    "        ste += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "98\n",
      "0\n",
      "100\n",
      "99+98+0+100 = 297\n",
      "297\n"
     ]
    }
   ],
   "source": [
    "print(nt)\n",
    "print(hem)\n",
    "print(ste)\n",
    "print(ctr)\n",
    "print(\"{}+{}+{}+{} = {}\".format(nt,hem,ste,ctr, nt+hem+ste+ctr))\n",
    "print(len(one_hot_Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from numpy import isnan\n",
    "\n",
    "print(True in isnan(X_test))\n",
    "print(True in isnan(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Construction du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv3D(filters = 14, kernel_size = 5, data_format=\"channels_first\",\n",
    "                     strides=1, padding= \"same\", activation = \"relu\", kernel_initializer=\"he_normal\",\n",
    "                     input_shape = (14,32,32,32)))\n",
    "    model.add(Conv3D(filters = 14, kernel_size = 3, data_format=\"channels_first\",\n",
    "                     strides=1, padding= \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(rate = 0.5))\n",
    "    model.add(MaxPool3D(pool_size = 4, strides = 1, padding = \"valid\"))\n",
    "    model.add(Dropout(rate = 0.5))\n",
    "    model.add(Flatten(data_format = \"channels_first\"))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(units = 3, activation = \"softmax\"))\n",
    "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_one():\n",
    "    input_layer = keras.Input(shape=(14, 32, 32, 32))\n",
    "    conv_1 = keras.layers.Conv3D(\n",
    "        filters = 32,\n",
    "        kernel_size = 5,\n",
    "        activation = \"relu\", \n",
    "        data_format = \"channels_first\",\n",
    "        padding = \"valid\"\n",
    "        )(input_layer)\n",
    "    dropout_1 = keras.layers.Dropout(rate=0.2)(conv_1)\n",
    "    conv_2 = keras.layers.Conv3D(\n",
    "        filters = 32,\n",
    "        kernel_size = 3,\n",
    "        activation = \"relu\", \n",
    "        data_format=\"channels_first\",\n",
    "        padding=\"valid\"\n",
    "        )(dropout_1)\n",
    "    max_pooling_1 = keras.layers.MaxPooling3D(\n",
    "        pool_size=(2,2,2),\n",
    "        strides=None,\n",
    "        padding=\"valid\",\n",
    "        data_format=\"channels_first\"\n",
    "        )(conv_2)\n",
    "    dropout_2 = keras.layers.Dropout(rate=0.4)(max_pooling_1)\n",
    "    flatten_1 = keras.layers.Flatten()(dropout_2)\n",
    "    dense_1 = keras.layers.Dense(units=100, activation=\"relu\")(flatten_1)\n",
    "    output_layer = keras.layers.Dense(units=3, activation=\"softmax\")(dense_1)\n",
    "    notdeepdrug_model = keras.Model(inputs=input_layer,outputs=output_layer)\n",
    "    notdeepdrug_model.compile(\n",
    "            optimizer=\"adam\", \n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\"]\n",
    "            )\n",
    "    return notdeepdrug_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 282 samples, validate on 15 samples\n",
      "Epoch 1/5\n",
      "282/282 [==============================] - 56s 197ms/step - loss: 6.1003 - accuracy: 0.3333 - val_loss: 1.1214 - val_accuracy: 0.2000\n",
      "Epoch 2/5\n",
      "282/282 [==============================] - 49s 173ms/step - loss: 1.0988 - accuracy: 0.3369 - val_loss: 1.0992 - val_accuracy: 0.2667\n",
      "Epoch 3/5\n",
      "282/282 [==============================] - 49s 173ms/step - loss: 1.0987 - accuracy: 0.3404 - val_loss: 1.0994 - val_accuracy: 0.2667\n",
      "Epoch 4/5\n",
      "282/282 [==============================] - 50s 176ms/step - loss: 1.0986 - accuracy: 0.3404 - val_loss: 1.0999 - val_accuracy: 0.2667\n",
      "Epoch 5/5\n",
      "282/282 [==============================] - 51s 182ms/step - loss: 1.0985 - accuracy: 0.3404 - val_loss: 1.1002 - val_accuracy: 0.2667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb09d95f7d0>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fct_model  = model_one()\n",
    "fct_model.fit(X_train, one_hot_Y_train, epochs = 10, batch_size = 20,\n",
    "              validation_split = 0.05, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        (None, 14, 32, 32, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_79 (Conv3D)           (None, 32, 28, 28, 28)    56032     \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 32, 28, 28, 28)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_80 (Conv3D)           (None, 32, 26, 26, 26)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_31 (MaxPooling (None, 32, 13, 13, 13)    0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 32, 13, 13, 13)    0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 70304)             0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 100)               7030500   \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 7,114,515\n",
      "Trainable params: 7,114,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fct_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 23s 73ms/step\n",
      "[1.0985779586630555, 0.3510971665382385]\n"
     ]
    }
   ],
   "source": [
    "evaluation = fct_model.evaluate(X_test, one_hot_Y_test, batch_size = 32)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = KerasClassifier(build_fn = model_one, epochs = 5, batch_size=20, verbose=0)\n",
    "kfold = KFold(n_splits = 5, shuffle=True)\n",
    "cv_result = cross_val_score(training, X_train, one_hot_Y_train, cv = kfold)\n",
    "print(cv_result)\n",
    "print(\"%.2f%%(%2d%%)\"%(cv_result.mean()*100, cv_result.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fct_model.predict(X_test, batch_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33652374 0.33085775 0.3326185 ]\n",
      "[0.33652768 0.33085352 0.33261874]\n",
      "[0.3366566  0.33067924 0.33266413]\n",
      "[0.3365169  0.33087912 0.332604  ]\n",
      "[0.33652157 0.3308713  0.33260715]\n",
      "[0.33652493 0.3308621  0.33261296]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33665532 0.33073848 0.33260623]\n",
      "[0.33652043 0.33087695 0.33260262]\n",
      "[0.33657536 0.33079764 0.3326269 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33669865 0.33067816 0.33262315]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651718 0.33088008 0.33260274]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33654356 0.33085513 0.3326013 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33654982 0.33084452 0.33260563]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33657557 0.33079404 0.33263046]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651763 0.330877   0.33260536]\n",
      "[0.33651894 0.33085236 0.33262876]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365172 0.3308801 0.3326027]\n",
      "[0.33663443 0.330738   0.33262762]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651718 0.33087978 0.3326031 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651754 0.33087978 0.3326027 ]\n",
      "[0.33652094 0.3308769  0.3326022 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33652616 0.33085793 0.3326159 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651808 0.33085942 0.33262256]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33653712 0.33085498 0.33260787]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33653417 0.33085367 0.3326122 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651596 0.33087474 0.33260933]\n",
      "[0.3366426  0.3307202  0.33263722]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651778 0.33087957 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33670065 0.33064348 0.33265588]\n",
      "[0.33661443 0.3307709  0.3326147 ]\n",
      "[0.33668834 0.33072013 0.33259153]\n",
      "[0.33651742 0.33087987 0.33260268]\n",
      "[0.33653542 0.33085492 0.33260962]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33687013 0.33044463 0.3326852 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33655792 0.3308266  0.33261552]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3366331  0.3307384  0.33262858]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651757 0.33087972 0.33260268]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651754 0.3308794  0.33260304]\n",
      "[0.3365256  0.33087212 0.33260226]\n",
      "[0.3365981  0.33078077 0.33262116]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651835 0.33087856 0.33260313]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365155 0.33087   0.3326145]\n",
      "[0.33652672 0.3308624  0.33261082]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365169 0.3308781 0.332605 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33652416 0.33087298 0.33260283]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33652526 0.3308705  0.33260426]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651808 0.33087888 0.3326031 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365293  0.3308638  0.33260682]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33655837 0.3308339  0.33260766]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33735347 0.33007    0.33257648]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651888 0.33087832 0.33260283]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33662635 0.3307511  0.33262253]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365431 0.3308332 0.3326236]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3366328  0.33075505 0.33261213]\n",
      "[0.33651838 0.33087876 0.33260286]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651814 0.33087867 0.33260316]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33655852 0.3308391  0.33260235]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365191  0.3308784  0.33260244]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33656278 0.3308268  0.33261043]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33662784 0.33077198 0.33260018]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651686 0.33088025 0.33260292]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365184  0.33087873 0.3326028 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33654803 0.3308344  0.33261758]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365646  0.33082974 0.3326057 ]\n",
      "[0.3365518  0.33084288 0.3326053 ]\n",
      "[0.33651865 0.3308786  0.33260283]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651784 0.33087927 0.3326029 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365554  0.33083606 0.33260858]\n",
      "[0.33652282 0.33087203 0.33260512]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651802 0.3308793  0.33260268]\n",
      "[0.3368908  0.33046192 0.33264732]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365546  0.33082953 0.33261585]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365418  0.3308389  0.33261928]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365214  0.33085763 0.33262098]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651808 0.33087474 0.3326072 ]\n",
      "[0.33653384 0.33085847 0.33260772]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33664966 0.33074626 0.33260408]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651707 0.33088014 0.33260277]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33652374 0.33087078 0.3326055 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33659682 0.33079407 0.3326091 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651865 0.33087736 0.33260402]\n",
      "[0.33657515 0.33075094 0.3326739 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33653614 0.33086026 0.33260363]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33652085 0.33087498 0.33260414]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33652386 0.33087274 0.33260342]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365433  0.33085805 0.33259866]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33659196 0.3307745  0.33263358]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651832 0.33087906 0.33260268]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33673605 0.33059168 0.3326723 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33666593 0.3306963  0.33263776]\n",
      "[0.3365223  0.33087245 0.33260524]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33658445 0.33080187 0.33261374]\n",
      "[0.33660358 0.33077037 0.3326261 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33653766 0.3308495  0.3326128 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33658025 0.3308013  0.33261842]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n",
      "[0.3365444 0.330835  0.3326206]\n",
      "[0.33652154 0.330875   0.33260354]\n",
      "[0.33651927 0.33087802 0.33260274]\n",
      "[0.33656943 0.33081064 0.3326199 ]\n",
      "[0.33651713 0.33088017 0.3326027 ]\n"
     ]
    }
   ],
   "source": [
    "for p in predictions:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    maxi = max(predictions[i,:])\n",
    "    if maxi == predictions[i, 0]:\n",
    "        classe = 0\n",
    "    elif maxi == predictions[i,1]:\n",
    "        classe = 1\n",
    "    elif maxi == predictions[i,2]:\n",
    "        classe = 2\n",
    "        \n",
    "    if (one_hot_Y_test[i, 0] == 1.0) and (classe == 0):\n",
    "        tp += 1\n",
    "    elif (one_hot_Y_test[i, 1] == 1.0) and (classe == 1):\n",
    "        tp += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 1.0) and (classe == 0):\n",
    "        fp += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 1.0) and (classe == 1):\n",
    "        fp += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 1.0) and (classe == 2):\n",
    "        tn += 1\n",
    "    elif (one_hot_Y_test[i, 2] == 0.0) and (classe == 2):\n",
    "        fn += 1\n",
    "        \n",
    "from math import sqrt\n",
    "\n",
    "print(\"TP:{:.2f}%\".format(tp*100/len(predictions)))\n",
    "print(\"FP:{:.2f}%\".format(fp*100/len(predictions)))\n",
    "print(\"TN:{:.2f}\".format(tn*100/len(predictions)))\n",
    "print(\"FN:{:.2f}\".format(fn*100/len(predictions)))\n",
    "print(\"ACC = {:.2f}%\".format((tp+tn)*100/(tp+tn+fp+fn)))\n",
    "print(\"PPV = {:.2f}%\".format(tp*100/(tp+fp)))\n",
    "print(\"TNR = {:.2f}%\".format(tn*100/(tn+fp)))\n",
    "print(\"TPR = {:.2f}%\".format(tp*100/(tp+fn)))\n",
    "print(\"FPR = {:.2f}%\".format(fp*100/(fp+tn)))\n",
    "print(\"MCC = {:.2f}\".format(((tn*tp)-(fp*fn))/sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
